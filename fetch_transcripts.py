import os, json, subprocess, sys, time
from pathlib import Path
from tqdm import tqdm
from youtube_transcript_api import (
    YouTubeTranscriptApi,
    TranscriptsDisabled,
    NoTranscriptFound,
    VideoUnavailable,
)

# You can change this to any YouTube channel/playlist URL.
# Default is Brandon Epstein's channel "Videos" tab.
CHANNEL_URL = os.getenv("CHANNEL_URL", "https://www.youtube.com/@BrandonEpsteinOfficial/videos").strip()

OUT_DIR = Path("output")
EP_DIR = OUT_DIR / "episodes"
OUT_DIR.mkdir(parents=True, exist_ok=True)
EP_DIR.mkdir(parents=True, exist_ok=True)

PROXY_ENV_VARS = (
    "HTTP_PROXY",
    "http_proxy",
    "HTTPS_PROXY",
    "https_proxy",
    "ALL_PROXY",
    "all_proxy",
)

def _env_without_proxies(env: dict) -> dict:
    updated = env.copy()
    for var in PROXY_ENV_VARS:
        updated.pop(var, None)
    return updated

def run_yt_dlp_list(url: str):
    """
    Use yt-dlp to list ALL videos (no API key) as JSON.
    """
    # --flat-playlist: no downloads, just metadata
    # -J: dump JSON
    # -I 1:9999: index range large enough to grab all
    base_cmd = [
        "yt-dlp", "--flat-playlist", "-J", "-I", "1:9999", url
    ]

    original_env = os.environ.copy()
    attempts = [
        ("direct", base_cmd + ["--proxy", ""], _env_without_proxies(original_env)),
        ("proxy", base_cmd, original_env),
    ]

    errors = []
    for label, cmd, env in attempts:
        result = subprocess.run(cmd, capture_output=True, text=True, env=env)
        if result.returncode == 0:
            if label == "direct":
                print("[INFO] yt-dlp succeeded without proxy")
            else:
                print("[INFO] yt-dlp fell back to proxy configuration")
            return json.loads(result.stdout), env
        stderr = result.stderr.strip()
        errors.append((label, stderr))

    for label, err in errors:
        if err:
            print(f"[ERROR] yt-dlp ({label}) failed:\n{err}", file=sys.stderr)
    joined = "\n".join(err for _, err in errors if err)
    if "Tunnel connection failed: 403" in joined:
        print(
            "[HINT] The configured HTTPS proxy rejected YouTube requests (403). "
            "Disable the proxy or provide one that allows *.youtube.com.",
            file=sys.stderr,
        )
    if "Failed to establish a new connection" in joined or "Network is unreachable" in joined:
        print(
            "[HINT] This environment cannot reach YouTube directly. "
            "Ensure outbound HTTPS access to youtube.com is available before retrying.",
            file=sys.stderr,
        )
    sys.exit(1)

def safe_name(s: str) -> str:
    keep = "".join(c for c in s if c.isalnum() or c in (" ", "-", "_"))
    return keep.strip()

def get_transcript_text(video_id: str) -> str:
    """
    Try human transcript first; fall back to auto-generated; else empty.
    """
    try:
        # Try in order of preference
        transcript = None
        listing = YouTubeTranscriptApi.list_transcripts(video_id)
        for lang in ("en", "en-US"):
            if listing.find_manually_created_transcript([lang]):
                transcript = listing.find_manually_created_transcript([lang]).fetch()
                break
        if transcript is None:
            # fall back to autogenerated English if available
            for lang in ("en", "en-US"):
                if listing.find_generated_transcript([lang]):
                    transcript = listing.find_generated_transcript([lang]).fetch()
                    break
        if not transcript:
            return ""
        text = " ".join(chunk["text"] for chunk in transcript if chunk.get("text"))
        return text.strip()
    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):
        return ""
    except Exception:
        return ""

def main():
    print(f"[INFO] Listing videos from: {CHANNEL_URL}")
    data, effective_env = run_yt_dlp_list(CHANNEL_URL)

    # Ensure downstream libraries use the same proxy configuration that worked
    # for yt-dlp. This matters because youtube-transcript-api honors
    # environment proxy variables in the same way.
    os.environ.clear()
    os.environ.update(effective_env)

    # yt-dlp returns a top-level dict. For channel pages:
    # - 'entries' contains video entries with 'id' and 'title'
    entries = data.get("entries") or []
    print(f"[INFO] Found {len(entries)} videos")

    merged_sections = []
    index_rows = []

    for entry in tqdm(entries, desc="Fetching transcripts"):
        vid = entry.get("id")
        title = (entry.get("title") or f"Video {vid}").replace("\n", " ").strip()
        url = f"https://www.youtube.com/watch?v={vid}"

        text = get_transcript_text(vid)
        section = [
            f"### {title}",
            f"URL: {url}",
        ]
        if text:
            section.append("")
            section.append(text)
        else:
            section.append("")
            section.append("(No transcript available)")
        merged_sections.append("\n".join(section) + "\n\n")

        # per-episode file
        per_path = EP_DIR / f"{safe_name(title)[:80]}_{vid}.txt"
        per_path.write_text("\n".join(section) + "\n", encoding="utf-8")

        index_rows.append({
            "title": title,
            "videoId": vid,
            "url": url,
            "has_transcript": bool(text),
        })

        # small polite delay
        time.sleep(0.1)

    # merged file
    merged_path = OUT_DIR / "BrandonEpstein_ALL_Transcripts.txt"
    merged_path.write_text("".join(merged_sections), encoding="utf-8")

    # index json
    (OUT_DIR / "index.json").write_text(json.dumps(index_rows, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"[DONE] Wrote {merged_path} and per-episode files in {EP_DIR}")

if __name__ == "__main__":
    main()
